{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Pipeline for Sentinnel2 data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import netCDF4 as nc\n",
    "import rasterio\n",
    "import numpy as np\n",
    "parent_dir = '/home/cos-bot/Desktop/ai4boundaries'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Extracing train,val and test data using csv</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:\n",
      "5319\n",
      "/home/cos-bot/Desktop/ai4boundaries/sentinel2/images/NL/NL_3141_S2_10m_256.nc\n",
      "5319\n",
      "/home/cos-bot/Desktop/ai4boundaries/sentinel2/masks/NL/NL_3141_S2label_10m_256.tif\n",
      "Val Data:\n",
      "1140\n",
      "/home/cos-bot/Desktop/ai4boundaries/sentinel2/images/AT/AT_10191_S2_10m_256.nc\n",
      "1140\n",
      "/home/cos-bot/Desktop/ai4boundaries/sentinel2/masks/AT/AT_10191_S2label_10m_256.tif\n",
      "Test Data:\n",
      "1139\n",
      "/home/cos-bot/Desktop/ai4boundaries/sentinel2/images/AT/AT_10038_S2_10m_256.nc\n",
      "1139\n",
      "/home/cos-bot/Desktop/ai4boundaries/sentinel2/masks/AT/AT_10038_S2label_10m_256.tif\n",
      "Mask Data:\n",
      "5319\n",
      "1140\n",
      "1139\n"
     ]
    }
   ],
   "source": [
    "#Paths of files to be extracted for CSV\n",
    "\n",
    "train_img_path = []\n",
    "train_mask_path =[]\n",
    "\n",
    "\n",
    "val_img_path = []\n",
    "val_mask_path = []\n",
    "\n",
    "test_img_path = []\n",
    "test_mask_path = []\n",
    "\n",
    "\n",
    "\n",
    "def read_train_data(csv_path,label):\n",
    "    train_list = []\n",
    "    mask_list = []\n",
    "\n",
    "    # Open the CSV file\n",
    "    with open(csv_path, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "\n",
    "        # Iterate over the rows\n",
    "        for row in reader:\n",
    "            split_value = row['split']\n",
    "\n",
    "            # Check if the row belongs to the 'train' split\n",
    "            if split_value == label:\n",
    "                mask_value = row['sentinel2_masks_file_url']\n",
    "                train_value = row['sentinel2_images_file_url']\n",
    "\n",
    "                # Append the values to the respective lists\n",
    "\n",
    "                # train_list.append(train_value)\n",
    "                # mask_list.append(mask_value)\n",
    "\n",
    "                mask_list.append(parent_dir+mask_value[67:])\n",
    "                train_list.append(parent_dir+train_value[67:])\n",
    "\n",
    "\n",
    "    # slice_strings_in_list(train_list)\n",
    "\n",
    "    return train_list, mask_list\n",
    "\n",
    "# Specify the CSV file path\n",
    "csv_path = '/home/cos-bot/Desktop/ai4boundaries/ai4boundaries_ftp_urls_sentinel2_split.csv'\n",
    "\n",
    "# Read the 'mask' and 'train' values for rows where 'split' is 'train'\n",
    "train_img_path, train_mask_path = read_train_data(csv_path,'train')\n",
    "val_img_path, val_mask_path = read_train_data(csv_path,'val')\n",
    "test_img_path, test_mask_path = read_train_data(csv_path,'test')\n",
    "\n",
    "\n",
    "# Print the train data lists\n",
    "print(\"Train Data:\")\n",
    "print(len(train_img_path))\n",
    "print(train_img_path[0])\n",
    "print(len(train_mask_path))\n",
    "print(train_mask_path[0])\n",
    "\n",
    "# Print the val data lists \n",
    "print(\"Val Data:\")\n",
    "print(len(val_img_path))\n",
    "print(val_img_path[0])\n",
    "print(len(val_mask_path))\n",
    "print(val_mask_path[0])\n",
    "\n",
    "\n",
    "# Print the test data lists\n",
    "print(\"Test Data:\")\n",
    "print(len(test_img_path))\n",
    "print(test_img_path[0])\n",
    "print(len(test_mask_path))\n",
    "print(test_mask_path[0])\n",
    "\n",
    "# print(parent_dir+train_data[0][53:])\n",
    "\n",
    "# Print the test data lists\n",
    "print(\"Mask Data:\")\n",
    "print(len(train_mask_path))\n",
    "print(len(val_mask_path))\n",
    "print(len(test_mask_path))\n",
    "\n",
    "# /home/prateekjha/Anit/ai4boundaries/sentinel2/images/AT/AT_164_S2_10m_256.nc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Reading images and masks from train,test and val paths</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cos-bot/Desktop/ai4boundaries/sentinel2/images/NL/NL_3141_S2_10m_256.nc\n",
      "/home/cos-bot/Desktop/ai4boundaries/sentinel2/masks/NL/NL_3141_S2label_10m_256.tif\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img_path =train_img_path[0]\n",
    "mask_path=train_mask_path[0]\n",
    "\n",
    "X_test = []\n",
    "\n",
    "print(img_path)\n",
    "print(mask_path)\n",
    "\n",
    "def create_np_4bands(dir_path,file_name):\n",
    "    file_name=[]\n",
    "    for img_path in dir_path:\n",
    "        \n",
    "        dataset = nc.Dataset(img_path)\n",
    "\n",
    "        # Access the three bands\n",
    "        band_B2 = dataset.variables['B2'][:][1]\n",
    "        band_B3 = dataset.variables['B3'][:][1]\n",
    "        band_B4 = dataset.variables['B4'][:][1]\n",
    "        band_B8 = dataset.variables['B8'][:][1]\n",
    "\n",
    "\n",
    "        # Normalize the bands (optional)\n",
    "        normalized_B2 = (band_B2 - band_B2.min()) / (band_B2.max() - band_B2.min())\n",
    "        normalized_B3 = (band_B3 - band_B3.min()) / (band_B3.max() - band_B3.min())\n",
    "        normalized_B4 = (band_B4 - band_B4.min()) / (band_B4.max() - band_B4.min())\n",
    "        normalized_B8 = (band_B8 - band_B8.min()) / (band_B8.max() - band_B8.min())\n",
    "\n",
    "        # Stack the normalized bands\n",
    "        stacked_image = np.dstack((normalized_B2, normalized_B3, normalized_B4,normalized_B8))\n",
    "        file_name.append(stacked_image)\n",
    "        \n",
    "        return file_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementation \n",
    "\n",
    "X_train=[]\n",
    "X_val=[]\n",
    "X_test=[]\n",
    "\n",
    "for img_path in train_img_path:\n",
    "    \n",
    "    dataset = nc.Dataset(img_path)\n",
    "\n",
    "    # Access the three bands\n",
    "    band_B2 = dataset.variables['B2'][:][1]\n",
    "    band_B3 = dataset.variables['B3'][:][1]\n",
    "    band_B4 = dataset.variables['B4'][:][1]\n",
    "    band_B8 = dataset.variables['B8'][:][1]\n",
    "\n",
    "\n",
    "    # Normalize the bands (optional)\n",
    "    normalized_B2 = (band_B2 - band_B2.min()) / (band_B2.max() - band_B2.min())\n",
    "    normalized_B3 = (band_B3 - band_B3.min()) / (band_B3.max() - band_B3.min())\n",
    "    normalized_B4 = (band_B4 - band_B4.min()) / (band_B4.max() - band_B4.min())\n",
    "    normalized_B8 = (band_B8 - band_B8.min()) / (band_B8.max() - band_B8.min())\n",
    "\n",
    "    # Stack the normalized bands\n",
    "    stacked_image = np.dstack((normalized_B2, normalized_B3, normalized_B4,normalized_B8))\n",
    "    X_train.append(stacked_image)\n",
    "\n",
    "\n",
    "# for img_path in val_img_path:\n",
    "    \n",
    "#     dataset = nc.Dataset(img_path)\n",
    "\n",
    "#     # Access the three bands\n",
    "#     band_B2 = dataset.variables['B2'][:][1]\n",
    "#     band_B3 = dataset.variables['B3'][:][1]\n",
    "#     band_B4 = dataset.variables['B4'][:][1]\n",
    "#     band_B8 = dataset.variables['B8'][:][1]\n",
    "\n",
    "\n",
    "#     # Normalize the bands (optional)\n",
    "#     normalized_B2 = (band_B2 - band_B2.min()) / (band_B2.max() - band_B2.min())\n",
    "#     normalized_B3 = (band_B3 - band_B3.min()) / (band_B3.max() - band_B3.min())\n",
    "#     normalized_B4 = (band_B4 - band_B4.min()) / (band_B4.max() - band_B4.min())\n",
    "#     normalized_B8 = (band_B8 - band_B8.min()) / (band_B8.max() - band_B8.min())\n",
    "\n",
    "#     # Stack the normalized bands\n",
    "#     stacked_image = np.dstack((normalized_B2, normalized_B3, normalized_B4,normalized_B8))\n",
    "#     X_val.append(stacked_image)\n",
    "\n",
    "# for img_path in test_img_path:\n",
    "    \n",
    "#     dataset = nc.Dataset(img_path)\n",
    "\n",
    "#     # Access the three bands\n",
    "#     band_B2 = dataset.variables['B2'][:][1]\n",
    "#     band_B3 = dataset.variables['B3'][:][1]\n",
    "#     band_B4 = dataset.variables['B4'][:][1]\n",
    "#     band_B8 = dataset.variables['B8'][:][1]\n",
    "\n",
    "\n",
    "#     # Normalize the bands (optional)\n",
    "#     normalized_B2 = (band_B2 - band_B2.min()) / (band_B2.max() - band_B2.min())\n",
    "#     normalized_B3 = (band_B3 - band_B3.min()) / (band_B3.max() - band_B3.min())\n",
    "#     normalized_B4 = (band_B4 - band_B4.min()) / (band_B4.max() - band_B4.min())\n",
    "#     normalized_B8 = (band_B8 - band_B8.min()) / (band_B8.max() - band_B8.min())\n",
    "\n",
    "#     # Stack the normalized bands\n",
    "#     stacked_image = np.dstack((normalized_B2, normalized_B3, normalized_B4,normalized_B8))\n",
    "#     X_test.append(stacked_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5319\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Not enough free space to write 5577375744 bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(X_train))\n\u001b[1;32m      4\u001b[0m \u001b[39m# print(len(X_val))\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# print(len(X_test))\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[39m#Saving the 4band imgs of ai4boundaries\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m np\u001b[39m.\u001b[39;49msave(\u001b[39m'\u001b[39;49m\u001b[39mX_train4.npy\u001b[39;49m\u001b[39m'\u001b[39;49m,X_train)\n\u001b[1;32m     10\u001b[0m \u001b[39m# np.save('X_val4.npy',X_val)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m# np.save('X_test4.npy',X_test)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m X_train_load \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mX_train4.npy\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36msave\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/npyio.py:529\u001b[0m, in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[39mwith\u001b[39;00m file_ctx \u001b[39mas\u001b[39;00m fid:\n\u001b[1;32m    528\u001b[0m     arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(arr)\n\u001b[0;32m--> 529\u001b[0m     \u001b[39mformat\u001b[39;49m\u001b[39m.\u001b[39;49mwrite_array(fid, arr, allow_pickle\u001b[39m=\u001b[39;49mallow_pickle,\n\u001b[1;32m    530\u001b[0m                        pickle_kwargs\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(fix_imports\u001b[39m=\u001b[39;49mfix_imports))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/format.py:687\u001b[0m, in \u001b[0;36mwrite_array\u001b[0;34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    686\u001b[0m     \u001b[39mif\u001b[39;00m isfileobj(fp):\n\u001b[0;32m--> 687\u001b[0m         array\u001b[39m.\u001b[39;49mtofile(fp)\n\u001b[1;32m    688\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m         \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m numpy\u001b[39m.\u001b[39mnditer(\n\u001b[1;32m    690\u001b[0m                 array, flags\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mexternal_loop\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbuffered\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mzerosize_ok\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m    691\u001b[0m                 buffersize\u001b[39m=\u001b[39mbuffersize, order\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m):\n",
      "\u001b[0;31mOSError\u001b[0m: Not enough free space to write 5577375744 bytes"
     ]
    }
   ],
   "source": [
    "#Print len of individual lists of data\n",
    "\n",
    "print(len(X_train))\n",
    "# print(len(X_val))\n",
    "# print(len(X_test))\n",
    "\n",
    "#Saving the 4band imgs of ai4boundaries\n",
    "\n",
    "np.save('X_train4.npy',X_train)\n",
    "# np.save('X_val4.npy',X_val)\n",
    "# np.save('X_test4.npy',X_test)\n",
    "\n",
    "X_train_load = np.load('X_train4.npy')\n",
    "train_shape = X_train_load.shape\n",
    "\n",
    "# X_val_load = np.load('X_val4.npy')\n",
    "# val_shape= X_val_load.shape\n",
    "\n",
    "# X_test_load = np.load('X_test4.npy')\n",
    "# test_shape =X_test_load.shape\n",
    "\n",
    "print(train_shape)\n",
    "# print(val_shape)\n",
    "# print(test_shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "\n",
    "for train_img,val_img,test_img in zip(X_train,X_val,X_test):\n",
    "\n",
    "    fig,axes = plt.subplots(1,3)\n",
    "    axes[0].imshow(train_img[:,:,:3])\n",
    "    axes[1].imshow(val_img[:,:,:3])\n",
    "    axes[2].imshow(test_img[:,:,:3])\n",
    "    plt.show()\n",
    "    count+=1\n",
    "    if(count>5):\n",
    "        break\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
